const { Innertube } = require('youtubei.js');
const fs = require('fs').promises;
const path = require('path');
const { execSync } = require('child_process');
const zlib = require('zlib');
const { promisify } = require('util');

const gzip = promisify(zlib.gzip);
const gunzip = promisify(zlib.gunzip);

const CONFIG = {
  BATCH_SIZE: 10,
  MAX_RETRIES: 3,
  RETRY_DELAY: 2000,
  MAX_RUNTIME_SECONDS: 280, // Leave 20 seconds buffer for cron every 5 minutes
  RATE_LIMIT_DELAY: 1000
};

class YouTubeScraperV2 {
  constructor() {
    this.youtube = null;
    this.startTime = Date.now();
    this.processedCount = 0;
    this.failedUrls = [];
  }

  async initialize() {
    this.youtube = await Innertube.create({
      retrieve_player: true,
      enable_safety_mode: false
    });
  }

  formatTime(ms) {
    const totalSeconds = Math.floor(ms / 1000);
    const hours = Math.floor(totalSeconds / 3600);
    const minutes = Math.floor((totalSeconds % 3600) / 60);
    const seconds = totalSeconds % 60;
    const milliseconds = ms % 1000;
    return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')},${String(milliseconds).padStart(3, '0')}`;
  }

  generateSRT(segments) {
    return segments.map((seg, i) => {
      const start = this.formatTime(Number(seg.s) || 0);
      const end = this.formatTime(Number(seg.e) || 0);
      return `${i + 1}\n${start} --> ${end}\n${seg.t}\n`;
    }).join('\n');
  }

  extractVideoId(url) {
    const patterns = [
      /(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)/,
      /^([a-zA-Z0-9_-]{11})$/
    ];

    for (const pattern of patterns) {
      const match = url.match(pattern);
      if (match) return match[1];
    }
    return null;
  }


  async checkIfProcessed(videoId) {
    try {
      // Check if video JSON already exists in API directory
      const videoPath = path.join('api', 'video', `${videoId}.json`);
      await fs.access(videoPath);
      return true;
    } catch {
      return false;
    }
  }

  async scrapeVideo(videoUrl, retries = 0) {
    const videoId = this.extractVideoId(videoUrl);

    if (!videoId) {
      console.error(`Invalid YouTube URL: ${videoUrl}`);
      return null;
    }

    if (await this.checkIfProcessed(videoId)) {
      console.log(`Skipping ${videoId} - already processed`);
      return { id: videoId, skipped: true };
    }

    try {
      console.log(`Processing video: ${videoId} (attempt ${retries + 1})`);

      const info = await this.youtube.getInfo(videoId);

      const videoData = {
        id: videoId,
        title: info.basic_info.title,
        author: info.basic_info.author,
        duration: info.basic_info.duration,
        view_count: info.basic_info.view_count,
        upload_date: info.primary_info?.published?.text || null,
        thumbnail_url: info.basic_info.thumbnail?.[0]?.url,
        url: videoUrl,
        scraped_at: new Date().toISOString()
      };

      const captionTracks = info.captions?.caption_tracks || [];
      console.log(`Found ${captionTracks.length} caption tracks`);

      const captions = {};

      // Helper to map transcript segments to compact format
      const mapSegments = (segments) => segments.map(s => ({
        s: s.start_ms || 0,
        e: s.end_ms || 0,
        t: s.snippet ? s.snippet.text : (s.text || '')
      }));

      // Try official transcript API once and reuse by selecting languages
      let transcriptInfo = null;
      try {
        transcriptInfo = await info.getTranscript();
      } catch (err) {
        console.warn(`getTranscript API unavailable for ${videoId}: ${err.message}`);
      }

      for (const track of captionTracks) {
        const languageCode = track.language_code;
        const isAutoGenerated = track.kind === 'asr';

        // Prefer human-created tracks; we'll still process ASR if humans are absent
        try {
          let segments = null;

          // Primary: YouTube transcript API
          if (transcriptInfo) {
            try {
              const langs = transcriptInfo.languages || [];
              const selected = langs.includes(languageCode)
                ? await transcriptInfo.selectLanguage(languageCode)
                : transcriptInfo;
              const transcript = selected.transcript;
              const segs = transcript?.content?.body?.initial_segments || [];
              if (segs.length) {
                segments = mapSegments(segs);
              }
            } catch (e) {
              console.warn(`Transcript API language switch failed (${languageCode}): ${e.message}`);
            }
          }

          // No fallback: if transcript API didn't yield segments, skip this language

          if (segments && segments.length) {
            captions[languageCode] = {
              auto: isAutoGenerated,
              segments
            };
          }
        } catch (error) {
          console.error(`Failed to download ${languageCode} captions:`, error.message);
        }

        await this.delay(100);
      }

      const record = {
        ...videoData,
        captions,
        has_captions: Object.keys(captions).length > 0,
        languages: Object.keys(captions)
      };

      // Write directly to API directory
      await this.writeVideoToAPI(record);

      this.processedCount++;
      return videoData;

    } catch (error) {
      console.error(`Failed to process ${videoId}:`, error.message);

      if (retries < CONFIG.MAX_RETRIES) {
        await this.delay(CONFIG.RETRY_DELAY * (retries + 1));
        return this.scrapeVideo(videoUrl, retries + 1);
      }

      this.failedUrls.push({ url: videoUrl, error: error.message });
      return null;
    }
  }

  async writeVideoToAPI(record) {
    const videoId = record.id;
    const apiVideoDir = path.join('api', 'video');
    await fs.mkdir(apiVideoDir, { recursive: true });

    // Write JSON with everything
    await fs.writeFile(
      path.join(apiVideoDir, `${videoId}.json`),
      JSON.stringify(record, null, 2)
    );

    // Write caption files
    for (const [lang, data] of Object.entries(record.captions || {})) {
      const prefix = data.auto ? 'auto_' : '';

      // Generate SRT
      const srt = data.segments.map((seg, i) => {
        const start = this.formatTime(seg.s);
        const end = this.formatTime(seg.e);
        return `${i + 1}\n${start} --> ${end}\n${seg.t}\n`;
      }).join('\n');

      await fs.writeFile(
        path.join(apiVideoDir, `${videoId}-${prefix}${lang}.srt`),
        srt
      );

      // Generate plain text
      const txt = data.segments.map(seg => seg.t).join(' ');
      await fs.writeFile(
        path.join(apiVideoDir, `${videoId}-${prefix}${lang}.txt`),
        txt
      );
    }
  }

  async generateStats() {
    const apiVideoDir = path.join('api', 'video');
    let totalVideos = 0;

    try {
      const files = await fs.readdir(apiVideoDir);
      totalVideos = files.filter(f => f.endsWith('.json') && !f.includes('-')).length;
    } catch {
      totalVideos = 0;
    }

    const stats = {
      total_videos: totalVideos,
      queued: 0,
      generated_at: new Date().toISOString()
    };

    await fs.writeFile(path.join('api', 'stats.json'), JSON.stringify(stats, null, 2));
    console.log(`Generated stats: ${totalVideos} total videos`);
  }

  async updateQueueStats(queuedCount) {
    try {
      const statsPath = path.join('api', 'stats.json');
      let stats = {};

      try {
        const existingStats = await fs.readFile(statsPath, 'utf-8');
        stats = JSON.parse(existingStats);
      } catch {
        stats = { total_videos: 0 };
      }

      stats.queued = queuedCount;
      stats.generated_at = new Date().toISOString();

      await fs.writeFile(statsPath, JSON.stringify(stats, null, 2));
      console.log(`Updated queue stats: ${queuedCount} queued`);
    } catch (error) {
      console.error('Failed to update queue stats:', error.message);
    }
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  isTimeUp() {
    const elapsed = Date.now() - this.startTime;
    return elapsed > CONFIG.MAX_RUNTIME_SECONDS * 1000;
  }

  async processBatch(urls) {
    const results = [];

    for (const url of urls) {
      if (this.isTimeUp()) {
        console.log('Time limit reached, stopping batch processing');
        break;
      }

      const result = await this.scrapeVideo(url);
      if (result && !result.skipped) {
        results.push(result);
      }

      await this.delay(CONFIG.RATE_LIMIT_DELAY);
    }

    return results;
  }

  async commitChanges() {
    if (!process.env.GITHUB_ACTIONS) return;

    try {
      execSync('git config user.name "GitHub Actions Bot"');
      execSync('git config user.email "actions@github.com"');
      execSync('git add api/');

      const message = `Update captions (${this.processedCount} videos) [skip ci]`;
      execSync(`git commit -m "${message}"`);
      execSync('git push');

      console.log(`Committed ${this.processedCount} videos`);
    } catch (error) {
      console.error('Failed to commit changes:', error.message);
    }
  }
}


async function getUnprocessedUrls() {
  const urlsFile = 'urls.txt';
  try {
    const content = await fs.readFile(urlsFile, 'utf-8');
    const urls = content.split('\n').filter(url => url.trim());
    return urls;
  } catch {
    return [];
  }
}

async function main() {
  try {
    const scraper = new YouTubeScraperV2();
    await scraper.initialize();

    let totalProcessed = 0;
    let lastCheckTime = Date.now();

    // Run for full 5 minutes, checking for URLs every 5 seconds
    while (!scraper.isTimeUp()) {
      const urls = await getUnprocessedUrls();

      if (urls.length > 0) {
        console.log(`Found ${urls.length} URLs to process`);

        // Update queue stats when URLs are found
        await scraper.updateQueueStats(urls.length);

        for (let i = 0; i < urls.length; i += CONFIG.BATCH_SIZE) {
          if (scraper.isTimeUp()) {
            console.log('Time limit reached, stopping');
            break;
          }

          const batch = urls.slice(i, i + CONFIG.BATCH_SIZE);
          await scraper.processBatch(batch);
          totalProcessed += batch.length;

          // Update remaining count
          const remaining = urls.length - Math.min(i + CONFIG.BATCH_SIZE, urls.length);
          await scraper.updateQueueStats(remaining);

          console.log(`Progress: ${Math.min(i + CONFIG.BATCH_SIZE, urls.length)}/${urls.length} URLs processed this round`);
        }

        // Clear processed URLs
        try {
          await fs.writeFile('urls.txt', '');
        } catch (e) {
          console.warn('Could not clear urls.txt:', e.message);
        }

        console.log(`Completed processing round. Total processed: ${totalProcessed}`);
        lastCheckTime = Date.now();
      } else {
        // No URLs found, wait 5 seconds before checking again
        const elapsed = Date.now() - lastCheckTime;
        if (elapsed < 5000) {
          await scraper.delay(5000 - elapsed);
        }
        lastCheckTime = Date.now();
        console.log('No URLs to process, checking again in 5 seconds...');
      }
    }

    // Clear queue and generate final stats
    await scraper.updateQueueStats(0);
    await scraper.generateStats();

    // Always regenerate static API after scrape
    try {
      const { StaticAPIGenerator } = require('./scripts/generate-static-api');
      const generator = new StaticAPIGenerator();
      await generator.generate();
    } catch (e) {
      console.error('Failed to regenerate static API:', e.message);
    }

    console.log(`
Summary:
- Total processed: ${totalProcessed} videos
- Failed: ${scraper.failedUrls.length} URLs
- Runtime: ${Math.floor((Date.now() - scraper.startTime) / 1000)}s
    `);

  } catch (error) {
    console.error('Fatal error:', error);
    process.exit(1);
  }
}

if (require.main === module) {
  main();
}

module.exports = { YouTubeScraperV2 };